{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sq8U3BtmhtRx"
   },
   "source": [
    "\n",
    "# **Running Pyspark in Colab**\n",
    "\n",
    "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 2.3.2 with hadoop 2.7, Java 8 and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab. One important note is that if you are new in Spark, it is better to avoid Spark 2.4.0 version since some people have already complained about its compatibility issue with python. \n",
    "Follow the steps to install the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lh5NCoc8fsSO",
    "outputId": "e0ee3fa8-85be-4454-a73c-44f231833f9b"
   },
   "outputs": [],
   "source": [
    "#spark sql imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILheUROOhprv"
   },
   "source": [
    "Now that you installed Spark and Java in Colab, it is time to set the environment path which enables you to run Pyspark in your Colab environment. Set the location of Java and Spark by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1b8k_OVf2QF"
   },
   "outputs": [],
   "source": [
    "#spark ML imports\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StringIndexer, CountVectorizer, IDF\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwrqMk3HiMiE"
   },
   "source": [
    "Run a local spark session to test your installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_Uz1NL4gHFx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.yarn.jars',\n",
       "  'local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/jars/*,local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/hive/*'),\n",
       " ('spark.yarn.appMasterEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.sql.queryExecutionListeners',\n",
       "  'com.cloudera.spark.lineage.NavigatorQueryListener'),\n",
       " ('spark.lineage.log.dir', '/var/log/spark/lineage'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'md01.rcc.local,md02.rcc.local'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip:/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/pyspark.zip'),\n",
       " ('spark.yarn.historyServer.address', 'http://hd01.rcc.local:18088'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.network.crypto.enabled', 'false'),\n",
       " ('spark.driver.port', '46618'),\n",
       " ('spark.executorEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.ui.enabled', 'true'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.dynamicAllocation.schedulerBacklogTimeout', '1'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1577383759214_7305'),\n",
       " ('spark.yarn.config.gatewayPath', '/opt/cloudera/parcels'),\n",
       " ('spark.extraListeners', 'com.cloudera.spark.lineage.NavigatorAppListener'),\n",
       " ('spark.port.maxRetries', '60'),\n",
       " ('spark.sql.warehouse.dir', '/user/hive/warehouse'),\n",
       " ('spark.app.name', 'Spark Updated Conf'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.log.persistToDfs.enabled', 'true'),\n",
       " ('spark.yarn.config.replacementPath', '{{HADOOP_COMMON_HOME}}/../../..'),\n",
       " ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.driver.appUIAddress', 'http://md01.rcc.local:4045'),\n",
       " ('spark.driver.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.ui.killEnabled', 'true'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.eventLog.dir', 'hdfs://nameservice1/user/spark/applicationHistory'),\n",
       " ('spark.dynamicAllocation.executorIdleTimeout', '60'),\n",
       " ('spark.executor.cores', '4'),\n",
       " ('spark.io.encryption.enabled', 'false'),\n",
       " ('spark.authenticate', 'false'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://md01.rcc.local:8088/proxy/application_1577383759214_7305,http://md02.rcc.local:8088/proxy/application_1577383759214_7305'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.id', 'application_1577383759214_7305'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS',\n",
       "  'md01.rcc.local:8088,md02.rcc.local:8088'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.yarn.historyServer.allowTracking', 'true'),\n",
       " ('spark.yarn.appMasterEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.shuffle.service.port', '7337'),\n",
       " ('spark.lineage.enabled', 'true'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.driver.host', 'md01.rcc.local'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.yarn.am.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.dynamicAllocation.minExecutors', '0'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.log.dfsDir', '/user/spark/driverLogs')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('ChicagoFoodInspectionML').getOrCreate()\n",
    "\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','4g')])\n",
    "\n",
    "#print spark configuration settings\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql.functions import broadcast\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import isnan, when, count, col, size\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uyu9jjuDb2p"
   },
   "outputs": [],
   "source": [
    "# Load app_id_info_join (loaded into RCC)\n",
    "app_id_info = spark.read.csv(\"./app_id_info_join_old.csv\", inferSchema=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJbR7fXfCojV"
   },
   "outputs": [],
   "source": [
    "# Drop repeating cols\n",
    "app_id_info = app_id_info.drop(\"_c8\",\"_c11\",\"_c13\",\"_c15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "slLAfjlaCoq5",
    "outputId": "39387fbd-4e84-40dc-b6ec-9f8e159f95dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- app_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- releasedDate: timestamp (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- requiredAge: integer (nullable = true)\n",
      " |-- isMultiplayer: integer (nullable = true)\n",
      " |-- achieveName: string (nullable = true)\n",
      " |-- achievePercent: double (nullable = true)\n",
      " |-- gamesDeveloper: string (nullable = true)\n",
      " |-- gamesGenre: string (nullable = true)\n",
      " |-- gamesPublisher: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns\n",
    "oldColumns = app_id_info.schema.names\n",
    "newColumns = [\"app_id\",\"title\",\"type\",\"price\", \"releasedDate\", \"rating\", \"requiredAge\", \"isMultiplayer\", \n",
    "              \"achieveName\", \"achievePercent\", \"gamesDeveloper\", \"gamesGenre\", \"gamesPublisher\"]\n",
    "  \n",
    "app_id_info = reduce(lambda app_id_info, idx: app_id_info.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), app_id_info)\n",
    "app_id_info.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAKqaoLrCouc"
   },
   "outputs": [],
   "source": [
    "# Rename app_id to app_id_1 to makesure we dont 2 columns with same name to drop later\n",
    "app_id_info = app_id_info.withColumnRenamed(\"app_id_1\", \"app_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YB_I1tSpCozG"
   },
   "outputs": [],
   "source": [
    "#df = spark.read.csv(\"./game2_df.csv\", inferSchema=True, header=True)\n",
    "df = spark.read.csv('/user/tamng/jwht/CleanData/game2_df.csv', inferSchema=True, header=True).coalesce(199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "AbGlkk4XCo6D",
    "outputId": "2e488d8f-1c1f-4c15-c1bd-cdc8e29de4a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- steam_id: long (nullable = true)\n",
      " |-- app_id: integer (nullable = true)\n",
      " |-- playtime_2weeks: integer (nullable = true)\n",
      " |-- playtime_forever: integer (nullable = true)\n",
      " |-- dateretrieved: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns\n",
    "oldColumns = df.schema.names\n",
    "newColumns = [\"steam_id\", \"app_id\",\"playtime_2weeks\", \"playtime_forever\",\"dateretrieved\"]\n",
    " \n",
    "df = reduce(lambda df, idx: df.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), df).cache() \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSg_EKtXD8NE"
   },
   "outputs": [],
   "source": [
    "#grouping by acheievements name and grabbing the count of the achievmenets - can we do this because we do not know if the achievement names are unique?\n",
    "app_id_info1 = app_id_info.groupby('app_id',\n",
    " 'title',\n",
    " 'type',\n",
    " 'price',\n",
    " 'releasedDate',\n",
    " 'rating',\n",
    " 'requiredAge',\n",
    " 'isMultiplayer',\n",
    " 'gamesDeveloper',\n",
    " 'gamesGenre',\n",
    " 'gamesPublisher').agg(F.count('achieveName').alias('achivements_cnt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_t2t7BwD8Ra"
   },
   "outputs": [],
   "source": [
    "#Select only the top 11 genres, label all others as 'Other' for gamesGenre\n",
    "app_id_info1 = app_id_info1.withColumn('gamesGenre',F.when(app_id_info1.gamesGenre.isin('Action','Adventure','Sports','Simulation','Casual',\n",
    "              'Strategy','RPG','Early Access','Free to Play','Violent','Indie'),app_id_info1.gamesGenre).otherwise('Other'))\n",
    "\n",
    "genre_list = ['Action','Adventure','Sports','Simulation','Casual',\n",
    "              'Strategy','RPG','Early Access','Free to Play','Violent','Indie','Other']\n",
    "\n",
    "for column in genre_list:\n",
    "    app_id_info1 = app_id_info1.withColumn(column,app_id_info1.gamesGenre.rlike(column).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCr8yUUoK-ma"
   },
   "outputs": [],
   "source": [
    "#in this expression can we potentially drop some of these grouping when making a new table\n",
    "exprs = {x: \"sum\" for x in genre_list}\n",
    "app_id_info1 = app_id_info1.groupby('app_id','title','type','price','releasedDate','rating','requiredAge','isMultiplayer','gamesDeveloper','gamesPublisher','achivements_cnt').agg(exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDCXSuYYL27q"
   },
   "outputs": [],
   "source": [
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Action)','Action')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Adventure)','Adventure')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Sports)','Sports')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Simulation)','Simulation')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Casual)','Casual')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Strategy)','Strategy')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(RPG)','RPG')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Early Access)','Early Access')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Free to Play)','Free to Play')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Violent)','Violent')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Other)','Other')\n",
    "app_id_info1 = app_id_info1.withColumnRenamed('sum(Indie)','Indie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XMwoFXP-cYt"
   },
   "outputs": [],
   "source": [
    "#JIM FEATURE ENGINEERING STARTS HERE\n",
    "#Total playtime and total games in library\n",
    "df2 = df.groupby('steam_id').agg(F.sum('playtime_forever').alias('total_playtime_forever'),\n",
    "                                 F.countDistinct('app_id').alias('total_games_owned'),\n",
    "                                 F.sum('playtime_2weeks').alias('total_playtime_2weeks'))\n",
    "                                 #F.countDistinct(F.when(df['playtime_forever']>0)).alias('total_games_played'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVg21q2E-cWr"
   },
   "outputs": [],
   "source": [
    "#Total games not played\n",
    "df2_notplayed = df.filter(df.playtime_forever==F.lit(0)).groupby('steam_id').agg(\\\n",
    "                            F.count('app_id').alias('total_games_not_played'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRoftyd3-cR1"
   },
   "outputs": [],
   "source": [
    "#Total games played\n",
    "df2_played = df.filter(df.playtime_forever>F.lit(0)).groupby('steam_id').agg(\n",
    "                            F.count('app_id').alias('total_games_played'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0BDL6H4-cQS"
   },
   "outputs": [],
   "source": [
    "#Percentage of games played\n",
    "df2_join = df2.join(df2_played,df2.steam_id==df2_played.steam_id,'left').drop(df2_played.steam_id)\n",
    "df2_join = df2_join.join(df2_notplayed,df2_join.steam_id==df2_notplayed.steam_id,'left').drop(df2_notplayed.steam_id)\n",
    "df2_join = df2_join.withColumn('pct_games_played',F.lit(df2_join.total_games_not_played)/F.lit(df2.total_games_owned))\n",
    "df2_join = df2_join.select('steam_id','total_playtime_forever','total_games_owned','total_playtime_2weeks','total_games_not_played','total_games_played','pct_games_played')\n",
    "df2_join = df2_join.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lQPdNPREtg7"
   },
   "outputs": [],
   "source": [
    "#Retrieve playtime by genre for each game, after joining to app_id_info to get genre\n",
    "df2_genre = df.join(app_id_info1,df.app_id==app_id_info1.app_id,'inner').drop(df.app_id)\n",
    "df2_genre = df2_genre.groupby('steam_id',\n",
    " 'app_id',\n",
    " 'title',\n",
    " 'type',\n",
    " 'price',\n",
    " 'releasedDate',\n",
    " 'rating',\n",
    " 'requiredAge',\n",
    " 'isMultiplayer',\n",
    " 'achivements_cnt',\n",
    " 'Indie',\n",
    " 'Other',\n",
    " 'Sports',\n",
    " 'Simulation',\n",
    " 'Strategy',\n",
    " 'RPG',\n",
    " 'Violent',\n",
    " 'Casual',\n",
    " 'Adventure',\n",
    " 'Early Access',\n",
    " 'Action',\n",
    " 'Free to Play').agg(F.max('gamesDeveloper').alias('gamesDeveloper'),F.max('gamesPublisher').alias('gamesPublisher'),\n",
    "                      F.max('playtime_2weeks').alias('playtime_2weeks'),F.max('playtime_forever').alias('playtime_forever'),\n",
    "                     F.max('dateretrieved').alias('date_retrieved'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ry4jaD-QEttP"
   },
   "outputs": [],
   "source": [
    "df2_genre1 = df2_genre.withColumn('action_playtime_forever',df2_genre.Action*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('adventure_playtime_forever',df2_genre.Adventure*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('simulation_playtime_forever',df2_genre.Simulation*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('sports_playtime_forever',df2_genre.Sports*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('casual_playtime_forever',df2_genre.Casual*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('strategy_playtime_forever',df2_genre.Strategy*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('rpg_playtime_forever',df2_genre.RPG*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('earlyaccess_playtime_forever',df2_genre['Early Access']*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('freetoplay_playtime_forever',df2_genre['Free To Play']*df2_genre.playtime_forever)\n",
    "df2_genre1 = df2_genre1.withColumn('violent_playtime_forever',df2_genre['Violent']*df2_genre.playtime_forever) \n",
    "df2_genre1 = df2_genre1.withColumn('other_playtime_forever',df2_genre['Other']*df2_genre.playtime_forever)\n",
    "\n",
    "#Total playtime and total games in library by genre\n",
    "df2_total = df2_genre1.groupby('steam_id').agg(F.sum('action_playtime_forever').alias('tt_action_playtime_forever'),\n",
    "                                F.sum('adventure_playtime_forever').alias('tt_adventure_playtime_forever'), \n",
    "                                F.sum('simulation_playtime_forever').alias('tt_simulation_playtime_forever'), \n",
    "                                F.sum('sports_playtime_forever').alias('tt_sports_playtime_forever'), \n",
    "                                F.sum('casual_playtime_forever').alias('tt_casual_playtime_forever'), \n",
    "                                F.sum('strategy_playtime_forever').alias('tt_strategy_playtime_forever'), \n",
    "                                F.sum('rpg_playtime_forever').alias('tt_rpg_playtime_forever'), \n",
    "                                F.sum('earlyaccess_playtime_forever').alias('tt_earlyaccess_playtime_forever'), \n",
    "                                F.sum('freetoplay_playtime_forever').alias('tt_freetoplay_playtime_forever'), \n",
    "                                F.sum('violent_playtime_forever').alias('tt_violent_playtime_forever'), \n",
    "                                F.sum('other_playtime_forever').alias('tt_other_playtime_forever'))\n",
    "\n",
    "#Average playtime and total games in library by genre\n",
    "df2_avgs = df2_genre1.groupby('steam_id').agg(F.avg('action_playtime_forever').alias('avg_action_playtime_forever'),\n",
    "                                F.avg('adventure_playtime_forever').alias('avg_adventure_playtime_forever'),\n",
    "                                F.avg('simulation_playtime_forever').alias('avg_simulation_playtime_forever'),\n",
    "                                F.avg('sports_playtime_forever').alias('avg_sports_playtime_forever'),\n",
    "                                F.avg('casual_playtime_forever').alias('avg_casual_playtime_forever'),\n",
    "                                F.avg('strategy_playtime_forever').alias('avg_strategy_playtime_forever'),\n",
    "                                F.avg('rpg_playtime_forever').alias('avg_rpg_playtime_forever'),\n",
    "                                F.avg('earlyaccess_playtime_forever').alias('avg_earlyaccess_playtime_forever'),\n",
    "                                F.avg('freetoplay_playtime_forever').alias('avg_freetoplay_playtime_forever'),\n",
    "                                F.avg('violent_playtime_forever').alias('avg_violent_playtime_forever'),       \n",
    "                                F.avg('other_playtime_forever').alias('avg_other_playtime_forever'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gn_sd7L5Et91"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, coalesce, greatest\n",
    "from pyspark.sql import Window\n",
    "#Favorite or Most played genre, least played genre(s)\n",
    "df2_most = df2_genre.withColumn('rank',F.dense_rank().over(Window.partitionBy(\"steam_id\").orderBy([\"playtime_forever\"])))\n",
    "df2_most = df2_most.filter(df2_most.rank==F.lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lz8BxN9U9LL"
   },
   "outputs": [],
   "source": [
    "df2_most = df2_most.withColumnRenamed('playtime_forever','playtime_mostplayedgenre')\n",
    "df2_most = df2_most.withColumnRenamed('Action','Mostplayed_Action')\n",
    "df2_most = df2_most.withColumnRenamed('Adventure','Mostplayed_Adventure')\n",
    "df2_most = df2_most.withColumnRenamed('Sports','Mostplayed_Sports')\n",
    "df2_most = df2_most.withColumnRenamed('Simulation','Mostplayed_Simulation')\n",
    "df2_most = df2_most.withColumnRenamed('Casual','Mostplayed_Casual')\n",
    "df2_most = df2_most.withColumnRenamed('Strategy','Mostplayed_Strategy')\n",
    "df2_most = df2_most.withColumnRenamed('RPG','Mostplayed_RPG')\n",
    "df2_most = df2_most.withColumnRenamed('Early Access','Mostplayed_Early_Access')\n",
    "df2_most = df2_most.withColumnRenamed('Free to Play','Mostplayed_FreetoPlay')\n",
    "df2_most = df2_most.withColumnRenamed('Violent','Mostplayed_Violent')\n",
    "df2_most = df2_most.withColumnRenamed('Indie','Mostplayed_Indie')\n",
    "df2_most = df2_most.withColumnRenamed('Other','Mostplayed_Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jb6jOFOrMvgK"
   },
   "outputs": [],
   "source": [
    "df2_most=df2_most.select('steam_id','playtime_mostplayedgenre','Mostplayed_Action','Mostplayed_Adventure','Mostplayed_Simulation',\n",
    "                         'Mostplayed_Casual','Mostplayed_Strategy','Mostplayed_RPG','Mostplayed_Early_Access','Mostplayed_FreetoPlay',\n",
    "                         'Mostplayed_Violent','Mostplayed_Indie','Mostplayed_Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N232fMJtEtrj"
   },
   "outputs": [],
   "source": [
    "#Count games by genre in user's library, everything will appear as Sum(NameofGenre) -- you need to clean this naming\n",
    "exprs = {x: \"sum\" for x in genre_list}\n",
    "df4 = df2_genre.groupBy(\"steam_id\").agg(exprs)\n",
    "\n",
    "df4 = df4.withColumnRenamed('sum(Action)','Action_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Adventure)','Adventure_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Sports)','Sports_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Simulation)','Simulation_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Casual)','Casual_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Strategy)','Strategy_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(RPG)','RPG_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Early Access)','EarlyAccess_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Free to Play)','FreetoPlay_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Violent)','Violent_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Indie)','Indie_Cnt')\n",
    "df4 = df4.withColumnRenamed('sum(Other)','Other_Cnt')\n",
    "#df4 = df2_genre.groupby('steam_id')['Action','Adventure','Sports','Simulation','Casual','Strategy','RPG','Early Access','Free To Play','Violent','Other'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgrxstr2Etl4"
   },
   "outputs": [],
   "source": [
    "#Join all temp tables\n",
    "df_masterjoin = df2_genre.join(df2_join,df2_join.steam_id==df2_genre.steam_id,'inner').drop(df2_join.steam_id)\n",
    "df_masterjoin = df_masterjoin.join(df2_total,df2_total.steam_id==df_masterjoin.steam_id,'inner').drop(df2_total.steam_id)\n",
    "df_masterjoin = df_masterjoin.join(df2_avgs,df2_avgs.steam_id==df_masterjoin.steam_id,'inner').drop(df2_avgs.steam_id)\n",
    "#df_masterjoin = df_masterjoin.join(df2_most,df2_most.steam_id==df_masterjoin.steam_id,'inner').drop(df2_most.steam_id)\n",
    "df_masterjoin = df_masterjoin.join(df4,df4.steam_id==df_masterjoin.steam_id,'inner').drop(df4.steam_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYy7rcIAli8c"
   },
   "outputs": [],
   "source": [
    "#Reorder features to bring steam_id to left most column\n",
    "df_masterjoin = df_masterjoin.select('steam_id',\n",
    " #'playtime_2weeks',\n",
    " 'playtime_forever',\n",
    " #'dateretrieved',\n",
    " 'app_id',\n",
    " 'title',\n",
    " 'type',\n",
    " 'price',\n",
    " 'releasedDate',\n",
    " #'rating',\n",
    " 'requiredAge',\n",
    " 'isMultiplayer',\n",
    " 'gamesDeveloper',\n",
    " 'gamesPublisher',\n",
    " 'achivements_cnt',\n",
    " 'Indie',\n",
    " 'Other',\n",
    " 'Sports',\n",
    " 'Simulation',\n",
    " 'Strategy',\n",
    " 'RPG',\n",
    " 'Violent',\n",
    " 'Casual',\n",
    " 'Adventure',\n",
    " 'Early Access',\n",
    " 'Action',\n",
    " 'Free to Play',\n",
    " 'total_playtime_forever',\n",
    " 'total_games_owned',\n",
    " 'total_playtime_2weeks',\n",
    " 'total_games_not_played',\n",
    " 'total_games_played',\n",
    " 'pct_games_played',\n",
    " #'tt_action_playtime_forever',\n",
    " #'tt_adventure_playtime_forever',\n",
    " #'tt_simulation_playtime_forever',\n",
    " #'tt_sports_playtime_forever',\n",
    " #'tt_casual_playtime_forever',\n",
    " #'tt_strategy_playtime_forever',\n",
    " #'tt_rpg_playtime_forever',\n",
    " #'tt_earlyaccess_playtime_forever',\n",
    " #'tt_freetoplay_playtime_forever',\n",
    " #'tt_violent_playtime_forever',\n",
    " #'tt_other_playtime_forever',\n",
    " 'Indie_Cnt',\n",
    " 'Other_Cnt',\n",
    " 'Sports_Cnt',\n",
    " 'Simulation_Cnt',\n",
    " 'Strategy_Cnt',\n",
    " 'RPG_Cnt',\n",
    " 'Violent_Cnt',\n",
    " 'Casual_Cnt',\n",
    " 'Adventure_Cnt',\n",
    " 'EarlyAccess_Cnt',\n",
    " 'Action_Cnt',\n",
    " 'FreetoPlay_Cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Fwk1zj2FS7w"
   },
   "outputs": [],
   "source": [
    "### Han's Edit's below for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "PCfQo6HlliWo",
    "outputId": "938763ec-db84-4d31-e4ed-92b463485119"
   },
   "outputs": [],
   "source": [
    "# Load app_id_info_join FINAL from tam/woo (loaded into RCC)\n",
    "app_id_info_new = spark.read.csv(\"./app_id_info_join_new.csv\", inferSchema=True, header=True) #ded_2.GetContentFile('app_id_info_join_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "LJwTujVnlihz",
    "outputId": "362a210f-b12f-4956-a8cd-171214468592"
   },
   "outputs": [],
   "source": [
    "app_id_cleaned = app_id_info_new.filter((app_id_info_new['positiveReviewPercent'] != '999'))\n",
    "app_id_cleaned = app_id_info_new[['title', 'rating', 'positiveReviewPercent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app_id',\n",
       " 'title',\n",
       " 'type',\n",
       " 'price',\n",
       " 'releaseDate',\n",
       " 'rating',\n",
       " 'ageRequirement',\n",
       " 'isMultiplayer',\n",
       " 'positiveReviewPercent']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_id_info_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNVLT-U6ue2y"
   },
   "outputs": [],
   "source": [
    "df_masterjoin1 = df_masterjoin.join(app_id_cleaned, df_masterjoin['title'] == app_id_cleaned['title'],'left').drop(df_masterjoin.title)\n",
    "df_masterjoin1 = df_masterjoin1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvD4bXO0TzyE"
   },
   "outputs": [],
   "source": [
    "#df_masterjoin1 = df_masterjoin.drop('dateretrieved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAG-bC-euc2J"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler #vectorizes the features\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_masterjoin1.write.csv('/user/jfang5/df_masterjoin1.csv')\n",
    "df_masterjoin1 = spark.read.csv(\"/user/jfang5/df_masterjoin1.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- steam_id: long (nullable = true)\n",
      " |-- playtime_forever: integer (nullable = true)\n",
      " |-- app_id: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- price: double (nullable = false)\n",
      " |-- releasedDate: timestamp (nullable = true)\n",
      " |-- requiredAge: integer (nullable = true)\n",
      " |-- isMultiplayer: integer (nullable = true)\n",
      " |-- gamesDeveloper: string (nullable = true)\n",
      " |-- gamesPublisher: string (nullable = true)\n",
      " |-- achivements_cnt: long (nullable = false)\n",
      " |-- Indie: long (nullable = true)\n",
      " |-- Other: long (nullable = true)\n",
      " |-- Sports: long (nullable = true)\n",
      " |-- Simulation: long (nullable = true)\n",
      " |-- Strategy: long (nullable = true)\n",
      " |-- RPG: long (nullable = true)\n",
      " |-- Violent: long (nullable = true)\n",
      " |-- Casual: long (nullable = true)\n",
      " |-- Adventure: long (nullable = true)\n",
      " |-- Early Access: long (nullable = true)\n",
      " |-- Action: long (nullable = true)\n",
      " |-- Free to Play: long (nullable = true)\n",
      " |-- total_playtime_forever: long (nullable = true)\n",
      " |-- total_games_owned: long (nullable = false)\n",
      " |-- total_playtime_2weeks: long (nullable = true)\n",
      " |-- total_games_not_played: long (nullable = true)\n",
      " |-- total_games_played: long (nullable = true)\n",
      " |-- pct_games_played: double (nullable = false)\n",
      " |-- Indie_Cnt: long (nullable = true)\n",
      " |-- Other_Cnt: long (nullable = true)\n",
      " |-- Sports_Cnt: long (nullable = true)\n",
      " |-- Simulation_Cnt: long (nullable = true)\n",
      " |-- Strategy_Cnt: long (nullable = true)\n",
      " |-- RPG_Cnt: long (nullable = true)\n",
      " |-- Violent_Cnt: long (nullable = true)\n",
      " |-- Casual_Cnt: long (nullable = true)\n",
      " |-- Adventure_Cnt: long (nullable = true)\n",
      " |-- EarlyAccess_Cnt: long (nullable = true)\n",
      " |-- Action_Cnt: long (nullable = true)\n",
      " |-- FreetoPlay_Cnt: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- positiveReviewPercent: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_masterjoin1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vX_njRzQ-ssT"
   },
   "source": [
    "Data type string of column title is not supported.\n",
    "Data type string of column type is not supported.\n",
    "Data type string of column releasedDate is not supported.\n",
    "Data type string of column gamesDeveloper is not supported.\n",
    "Data type string of column gamesPublisher is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNNQFHPfkqNQ"
   },
   "outputs": [],
   "source": [
    "df_masterjoin2 = df_masterjoin1.withColumn('year_released',F.year('releasedDate'))\n",
    "df_masterjoin2 = df_masterjoin1.drop('title', 'type', 'releasedDate', 'gamesDeveloper', 'gamesPublisher','steam_id','rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fcoxra9uXT4_",
    "outputId": "acf21749-6437-407d-b755-a9b816c8e871"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1282418"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masterjoin2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "KnUyEpBHPul0",
    "outputId": "dc1c8d66-684f-45b9-803e-862ac4835a8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['playtime_forever',\n",
       " 'app_id',\n",
       " 'price',\n",
       " 'requiredAge',\n",
       " 'isMultiplayer',\n",
       " 'achivements_cnt',\n",
       " 'Indie',\n",
       " 'Other',\n",
       " 'Sports',\n",
       " 'Simulation',\n",
       " 'Strategy',\n",
       " 'RPG',\n",
       " 'Violent',\n",
       " 'Casual',\n",
       " 'Adventure',\n",
       " 'Early Access',\n",
       " 'Action',\n",
       " 'Free to Play',\n",
       " 'total_playtime_forever',\n",
       " 'total_games_owned',\n",
       " 'total_playtime_2weeks',\n",
       " 'total_games_not_played',\n",
       " 'total_games_played',\n",
       " 'pct_games_played',\n",
       " 'Indie_Cnt',\n",
       " 'Other_Cnt',\n",
       " 'Sports_Cnt',\n",
       " 'Simulation_Cnt',\n",
       " 'Strategy_Cnt',\n",
       " 'RPG_Cnt',\n",
       " 'Violent_Cnt',\n",
       " 'Casual_Cnt',\n",
       " 'Adventure_Cnt',\n",
       " 'EarlyAccess_Cnt',\n",
       " 'Action_Cnt',\n",
       " 'FreetoPlay_Cnt',\n",
       " 'positiveReviewPercent']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masterjoin2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPZkO_3qRYTx"
   },
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = [i for i in df_masterjoin2.columns if i != 'playtime_forever'], outputCol = 'features') #[i for i in df_masterjoin2.columns if i != 'price']\n",
    "vectorAssembler.setHandleInvalid(\"skip\").transform(df_masterjoin2)\n",
    "v_df_masterjoin = vectorAssembler.transform(df_masterjoin2)\n",
    "v_df_masterjoin = v_df_masterjoin.select(['features', 'playtime_forever'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeY4qLUg80D0"
   },
   "outputs": [],
   "source": [
    "v_df_masterjoin = v_df_masterjoin.fillna(0)\n",
    "splits = v_df_masterjoin.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6-_sVUoFgaZ"
   },
   "source": [
    "LR with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWIBJm1QAB9Z"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol='playtime_forever') #label col has to be label?\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"playtime_forever\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kL7q5eZsDpzB"
   },
   "outputs": [],
   "source": [
    "grid = (ParamGridBuilder().addGrid(lr.maxIter, [5, 10]) \\\n",
    "                                .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "                                .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "                                .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urox6IYdFYsH"
   },
   "outputs": [],
   "source": [
    "lr_cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, \\\n",
    "                        evaluator=evaluator, numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqwzugFrFa0K"
   },
   "outputs": [],
   "source": [
    "#Fit Linear Regression Model\n",
    "lr_model = lr_cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "tUzyTxRCFm6H",
    "outputId": "24a0173b-6ddd-4133-cb2c-fae35f5e9dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of the model is [-0.0036384708984676865,24.592333111453748,-5.1519881721697915,259.53645035098697,8.524469136769724,-357.8450684819402,-127.84180417064037,-342.5475995368185,162.40671603489199,-97.56596665781385,691.2125008526195,0.0,-158.56992660005372,-152.5191193372339,-100.24573275360235,-391.3493004349811,855.8432068494642,0.009528296728404918,-0.3404730165886879,0.00893004193454783,0.49482557527404414,-4.233960490440863,-962.9204188579632,10.212541621308622,23.342305313534677,-4.952501163254995,-0.38163875669377567,-10.768730182295775,-12.910776629212771,0.0,3.1309729702095432,9.462976915001532,26.846128149712165,-11.011879936954521,-23.003279220210363,5.527216564652625]\n",
      "The Intercept of the model is : -10076.885085883614\n"
     ]
    }
   ],
   "source": [
    "bestModel = lr_model.bestModel\n",
    "\n",
    "print(\"The coefficient of the model is \" + str(bestModel.coefficients))\n",
    "print(\"The Intercept of the model is : \" + str(bestModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "2P1WKg8q6Pb7",
    "outputId": "10d294fe-f7c8-4507-c3ed-4b8a1f1172e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6221.471612\n",
      "r2: 0.051977\n",
      "MAE: 1616.112751\n"
     ]
    }
   ],
   "source": [
    "#RMSE measures the differences between predicted values by the model and the actual values. However, RMSE alone is meaningless until we compare with the actual “MV” value, such as mean, min and max. After such comparison, our RMSE looks pretty good.\n",
    "trainingSummary = bestModel.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n",
    "print('MAE: %f' % trainingSummary.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "GHD-gVL5XKEP",
    "outputId": "25b7c3c3-27e4-4456-967a-6257f4353f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+--------------------+\n",
      "|        prediction|playtime_forever|            features|\n",
      "+------------------+----------------+--------------------+\n",
      "|142.61850466545184|               7|(36,[0,1,2,3,4,5,...|\n",
      "|  570.622298840708|             141|(36,[0,1,2,3,4,5,...|\n",
      "|1215.8711300663108|            2757|(36,[0,1,2,3,4,5,...|\n",
      "| 894.7216097409437|             122|(36,[0,1,2,3,4,5,...|\n",
      "| 682.9565667657589|               0|(36,[0,1,2,3,4,5,...|\n",
      "+------------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test aspect to check with actuals\n",
    "lr_predictions1 = bestModel.transform(test_df)\n",
    "lr_predictions1.select(\"prediction\",\"playtime_forever\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "GGRNrZlwX891",
    "outputId": "f391cbe8-8691-4217-c832-f534a8fcaf72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.052101\n",
      "MSE 3.85563e+07\n",
      "MAE 1617.63\n"
     ]
    }
   ],
   "source": [
    "# how to evaluate the lr predictions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"playtime_forever\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions1))\n",
    "\n",
    "print(\"MSE %g\" % lr_evaluator.evaluate(lr_predictions1, {lr_evaluator.metricName: \"mse\"}))\n",
    "\n",
    "print(\"MAE %g\" % lr_evaluator.evaluate(lr_predictions1, {lr_evaluator.metricName: \"mae\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zG74h6dQ9Nkp"
   },
   "outputs": [],
   "source": [
    "# eval = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# # Root Mean Square Error\n",
    "# rmse = eval.evaluate(lr_predictions)\n",
    "# print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# # Mean Square Error\n",
    "# mse = eval.evaluate(lr_predictions, {eval.metricName: \"mse\"})\n",
    "# print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# # Mean Absolute Error\n",
    "# mae = eval.evaluate(lr_predictions, {eval.metricName: \"mae\"})\n",
    "# print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# # r2 - coefficient of determination\n",
    "# r2 = eval.evaluate(lr_predictions, {eval.metricName: \"r2\"})\n",
    "# print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1sMLNtIlEzU9"
   },
   "outputs": [],
   "source": [
    "#Decision Tree Regression Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- playtime_forever: integer (nullable = true)\n",
      " |-- app_id: integer (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- requiredAge: integer (nullable = true)\n",
      " |-- isMultiplayer: integer (nullable = true)\n",
      " |-- achivements_cnt: long (nullable = false)\n",
      " |-- Indie: long (nullable = true)\n",
      " |-- Other: long (nullable = true)\n",
      " |-- Sports: long (nullable = true)\n",
      " |-- Simulation: long (nullable = true)\n",
      " |-- Strategy: long (nullable = true)\n",
      " |-- RPG: long (nullable = true)\n",
      " |-- Violent: long (nullable = true)\n",
      " |-- Casual: long (nullable = true)\n",
      " |-- Adventure: long (nullable = true)\n",
      " |-- Early Access: long (nullable = true)\n",
      " |-- Action: long (nullable = true)\n",
      " |-- Free to Play: long (nullable = true)\n",
      " |-- total_playtime_forever: long (nullable = true)\n",
      " |-- total_games_owned: long (nullable = false)\n",
      " |-- total_playtime_2weeks: long (nullable = true)\n",
      " |-- total_games_not_played: long (nullable = true)\n",
      " |-- total_games_played: long (nullable = true)\n",
      " |-- pct_games_played: double (nullable = false)\n",
      " |-- Indie_Cnt: long (nullable = true)\n",
      " |-- Other_Cnt: long (nullable = true)\n",
      " |-- Sports_Cnt: long (nullable = true)\n",
      " |-- Simulation_Cnt: long (nullable = true)\n",
      " |-- Strategy_Cnt: long (nullable = true)\n",
      " |-- RPG_Cnt: long (nullable = true)\n",
      " |-- Violent_Cnt: long (nullable = true)\n",
      " |-- Casual_Cnt: long (nullable = true)\n",
      " |-- Adventure_Cnt: long (nullable = true)\n",
      " |-- EarlyAccess_Cnt: long (nullable = true)\n",
      " |-- Action_Cnt: long (nullable = true)\n",
      " |-- FreetoPlay_Cnt: long (nullable = true)\n",
      " |-- year_released: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_masterjoin2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "xLOM7t5w9NiQ",
    "outputId": "bf058b8b-cf7e-4f28-c8da-4a6a877d5576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on train data = 5980.68\n",
      "R2 on train data 0.123942\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 6035.23\n",
      "MSE 3.6424e+07\n",
      "R2 on test data 0.12338\n",
      "MAE 1379.28\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'playtime_forever', maxBins = 500, maxDepth = 4)\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "dt_predictions_train = dt_model.transform(train_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"playtime_forever\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions_train)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse)\n",
    "print(\"R2 on train data %g\" % dt_evaluator.evaluate(dt_predictions_train, {dt_evaluator.metricName: \"r2\"}))\n",
    "\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"playtime_forever\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"\\nRoot Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "print(\"MSE %g\" % dt_evaluator.evaluate(dt_predictions, {dt_evaluator.metricName: \"mse\"}))\n",
    "print(\"R2 on test data %g\" % dt_evaluator.evaluate(dt_predictions, {dt_evaluator.metricName: \"r2\"}))\n",
    "print(\"MAE %g\" % dt_evaluator.evaluate(dt_predictions, {dt_evaluator.metricName: \"mae\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F7I7YPkm9Nfi",
    "outputId": "0b1552a1-d392-47f6-898d-12ea1a144d8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(36, {0: 0.0783, 1: 0.0099, 4: 0.3071, 10: 0.0237, 17: 0.3012, 21: 0.2799})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OLd9a8zKlARD",
    "outputId": "8821640a-f410-4ba0-eda8-42daaa196c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playtime_forever requiredAge isMultiplayer achivements_cnt Other RPG Violent total_playtime_forever total_games_played\n"
     ]
    }
   ],
   "source": [
    "print([i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][0],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][2],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][3],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][4],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][6],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][10],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][11],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][17],\n",
    "[i for i in [i for i in [i for i in [i for i in [i for i in df_masterjoin2.columns if i != 'price'] if i !='title_index']if i !='releasedDate_index']if i !='gamesDeveloper_index']if i !='gamesPublisher_index'][21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Ycc22MTBEWIM",
    "outputId": "d142eaa7-1f8d-4c02-b80e-7580bfa6252c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gbt_model = gbt.fit(train_df)\\n\\n###\\ngbt_predictions1 = gbt_model.transform(train_df)\\ngbt_predictions1.select(\\'prediction\\', \\'playtime_forever\\', \\'features\\').show(5)\\nrmse = gbt_evaluator.evaluate(gbt_predictions1)\\nprint(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse)\\nprint(\"MSE TRAIN %g\" % gbt_evaluator.evaluate(gbt_predictions1, {gbt_evaluator.metricName: \"mse\"}))\\nprint(\"R2 on train data %g\" % gbt_evaluator.evaluate(gbt_predictions1, {gbt_evaluator.metricName: \"r2\"}))\\nprint(\"MAE train %g\" % gbt_evaluator.evaluate(gbt_predictions1, {gbt_evaluator.metricName: \"mae\"}))\\n###\\ngbt_predictions = gbt_model.transform(test_df)\\ngbt_predictions.select(\\'prediction\\', \\'playtime_forever\\', \\'features\\').show(5)\\ngbt_evaluator = RegressionEvaluator(\\n    labelCol=\"playtime_forever\", predictionCol=\"prediction\", metricName=\"rmse\")\\nrmse = gbt_evaluator.evaluate(gbt_predictions)\\nprint(\"\\nRoot Mean Squared Error (RMSE) on test data = %g\" % rmse)\\nprint(\"MSE %g\" % gbt_evaluator.evaluate(gbt_predictions, {gbt_evaluator.metricName: \"mse\"}))\\nprint(\"R2 on test data %g\" % gbt_evaluator.evaluate(gbt_predictions, {gbt_evaluator.metricName: \"r2\"}))\\nprint(\"MAE %g\" % gbt_evaluator.evaluate(gbt_predictions, {gbt_evaluator.metricName: \"mae\"}))'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"playtime_forever\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'playtime_forever', maxIter=10)\n",
    "'''gbt_model = gbt.fit(train_df)\n",
    "\n",
    "###\n",
    "gbt_predictions1 = gbt_model.transform(train_df)\n",
    "gbt_predictions1.select('prediction', 'playtime_forever', 'features').show(5)\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions1)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse)\n",
    "print(\"MSE TRAIN %g\" % gbt_evaluator.evaluate(gbt_predictions1, {gbt_evaluator.metricName: \"mse\"}))\n",
    "print(\"R2 on train data %g\" % gbt_evaluator.evaluate(gbt_predictions1, {gbt_evaluator.metricName: \"r2\"}))\n",
    "print(\"MAE train %g\" % gbt_evaluator.evaluate(gbt_predictions1, {gbt_evaluator.metricName: \"mae\"}))\n",
    "###\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'playtime_forever', 'features').show(5)\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"playtime_forever\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"\\nRoot Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"MSE %g\" % gbt_evaluator.evaluate(gbt_predictions, {gbt_evaluator.metricName: \"mse\"}))\n",
    "print(\"R2 on test data %g\" % gbt_evaluator.evaluate(gbt_predictions, {gbt_evaluator.metricName: \"r2\"}))\n",
    "print(\"MAE %g\" % gbt_evaluator.evaluate(gbt_predictions, {gbt_evaluator.metricName: \"mae\"}))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xlzVVqwEWNm"
   },
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, [4,5])\n",
    "             .addGrid(gbt.maxBins, [250,500])\n",
    "             .addGrid(gbt.maxIter, [10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jz_u_BGhKc9_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method JavaModelWrapper.__del__ of <pyspark.mllib.evaluation.MulticlassMetrics object at 0x7feb1e8ccba8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/mllib/common.py\", line 142, in __del__\n",
      "AttributeError: 'MulticlassMetrics' object has no attribute '_sc'\n"
     ]
    }
   ],
   "source": [
    "cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=gbt_evaluator, numFolds=2)\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "V5zIMArKEWL1",
    "outputId": "08e9ab10-bb8d-420a-e5ea-30d5762623b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+--------------------+\n",
      "|       prediction|playtime_forever|            features|\n",
      "+-----------------+----------------+--------------------+\n",
      "|545.9614189462898|              21|(36,[0,1,2,3,4,5,...|\n",
      "|580.2965581062791|              25|(36,[0,1,2,3,4,5,...|\n",
      "|542.3691439662712|             898|(36,[0,1,2,3,4,5,...|\n",
      "| 603.030644179706|             282|(36,[0,1,2,3,4,5,...|\n",
      "|759.5331650638544|             522|(36,[0,1,2,3,4,5,...|\n",
      "+-----------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on train data = 5689.27\n",
      "MSE TRAIN 3.23678e+07\n",
      "R2 on train data 0.207232\n",
      "MAE train 1292.05\n"
     ]
    }
   ],
   "source": [
    "gbestModel = cvModel.bestModel\n",
    "\n",
    "gb_predictions = gbestModel.transform(train_df)\n",
    "gb_predictions.select(\"prediction\",\"playtime_forever\",\"features\").show(5)\n",
    "\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"playtime_forever\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gb_predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse)\n",
    "print(\"MSE TRAIN %g\" % gbt_evaluator.evaluate(gb_predictions, {gbt_evaluator.metricName: \"mse\"}))\n",
    "print(\"R2 on train data %g\" % gbt_evaluator.evaluate(gb_predictions, {gbt_evaluator.metricName: \"r2\"}))\n",
    "print(\"MAE train %g\" % gbt_evaluator.evaluate(gb_predictions, {gbt_evaluator.metricName: \"mae\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8gZluMM5jbzG",
    "outputId": "cffb7cf2-e969-4189-941d-847c66076bf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBTRegressionModel (uid=GBTRegressor_7d3d22944f79) with 10 trees"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "Ror7XVT0iVvQ",
    "outputId": "cfbc2f5f-66f5-4aff-d3a6-a11afffc22ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+--------------------+\n",
      "|       prediction|playtime_forever|            features|\n",
      "+-----------------+----------------+--------------------+\n",
      "|848.8344824067185|               7|(36,[0,1,2,3,4,5,...|\n",
      "|509.7372365694996|             141|(36,[0,1,2,3,4,5,...|\n",
      "|1977.183526591758|            2757|(36,[0,1,2,3,4,5,...|\n",
      "| 850.752186698694|             122|(36,[0,1,2,3,4,5,...|\n",
      "|474.8478295548297|               0|(36,[0,1,2,3,4,5,...|\n",
      "+-----------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 5762.36\n",
      "MSE 3.32048e+07\n",
      "R2 on test data 0.200856\n",
      "MAE 1294.91\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "gb_predictions_test = gbestModel.transform(test_df)\n",
    "gb_predictions_test.select('prediction', 'playtime_forever', 'features').show(5)\n",
    "\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"playtime_forever\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gb_predictions_test)\n",
    "\n",
    "print(\"\\nRoot Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"MSE %g\" % gbt_evaluator.evaluate(gb_predictions_test, {gbt_evaluator.metricName: \"mse\"}))\n",
    "print(\"R2 on test data %g\" % gbt_evaluator.evaluate(gb_predictions_test, {gbt_evaluator.metricName: \"r2\"}))\n",
    "print(\"MAE %g\" % gbt_evaluator.evaluate(gb_predictions_test, {gbt_evaluator.metricName: \"mae\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JumN_TK_ljgT"
   },
   "source": [
    "# Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masterjoin2 = df_masterjoin2.withColumn('played_or_not',F.when(df_masterjoin2.playtime_forever>0,F.lit(1)).otherwise(F.lit(0)))\n",
    "#df_masterjoin2.groupby('played_or_not').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masterjoin2 = df_masterjoin2.drop('playtime_forever')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "7RSvw_Tz1UjE",
    "outputId": "fc5eec66-dadf-4eab-af25-98111278f62d"
   },
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = [i for i in df_masterjoin2.columns if i != 'played_or_not'], outputCol = 'features') #\n",
    "v_df_masterjoin = vectorAssembler.transform(df_masterjoin2)\n",
    "v_df_masterjoin = v_df_masterjoin.select(['features', 'played_or_not'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7VO_gmH06ud"
   },
   "outputs": [],
   "source": [
    "splits = v_df_masterjoin.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H09_N0joue20"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logr = LogisticRegression(featuresCol = 'features', labelCol = 'played_or_not', maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/software/Anaconda3-5.1.0-hadoop/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-a4cde633592c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcv_logr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatorParamMaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbt_evaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run cross validations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_logr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.1.0-hadoop/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.1.0-hadoop/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.aggregationDepth,[2])\\\n",
    "    .addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .addGrid(lr.maxIter,[10])\\\n",
    "    .addGrid(lr.regParam,[0.01, 2.0]) \\\n",
    "    .build()\n",
    "\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"played_or_not\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "cv_logr = CrossValidator(estimator=logr, estimatorParamMaps=paramGrid, evaluator=gbt_evaluator, numFolds=2)\n",
    "# Run cross validations\n",
    "lrModel = cv_logr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+\n",
      "|prediction|played_or_not|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "F1 on train data = 0.716352\n",
      "15383915 4851615 7347023 4064980 0.7602427512400218 0.7909917247226642 0.7753124809040323\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#lrbestModel = lrModel.bestModel\n",
    "\n",
    "results = lrModel.transform(train_df)\n",
    "results.select('prediction', 'played_or_not', 'features').show(5)\n",
    "\n",
    "f1 = gbt_evaluator.evaluate(results)\n",
    "print(\"\\nF1 on train data = %g\" % f1)\n",
    "\n",
    "TP = results.filter((results.prediction==1) & (results.played_or_not==1)).count()\n",
    "FP = results.filter((results.prediction==1) & (results.played_or_not!=1)).count()\n",
    "TN = results.filter((results.prediction==0) & (results.played_or_not==0)).count()\n",
    "FN = results.filter((results.prediction==0) & (results.played_or_not!=0)).count()\n",
    "\n",
    "pr = TP/(TP+FP)\n",
    "rc = TP/(TP+FN)\n",
    "f1 = (2*pr*rc)/(pr+rc)\n",
    "print(TP,FP,TN,FN,pr,rc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lrbestModel.transform(test_df)\n",
    "predictions_test.select('prediction', 'played_or_not', 'features').show(5)\n",
    "\n",
    "f1 = gbt_evaluator.evaluate(predictions_test)\n",
    "print(\"\\nF1 on test data = %g\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "juD04_892kxi",
    "outputId": "1ad545d0-aea1-4cdc-fe62-541e6b20ab72"
   },
   "outputs": [],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lGsQCJMM3Fug",
    "outputId": "d97cee77-bd2c-4844-e3d1-dac4224e0de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Params.explainParams of LogisticRegressionModel: uid = LogisticRegression_7b14ffab857c, numClasses = 2, numFeatures = 37>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrbestModel.explainParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QuawWnVue2_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.6666527819054636\n",
      "0.6666181533548772\n",
      "0.6666181533548772\n",
      "0.6665835009808695\n",
      "0.6665835009808695\n",
      "0.6665606634534205\n",
      "0.666483037894898\n",
      "0.6661413701545481\n",
      "0.6653948042538465\n",
      "0.6633384561881391\n",
      "0.6583850775403209\n",
      "0.6470669791708894\n",
      "0.6255294361023934\n",
      "+--------------------+--------------------+\n",
      "|                 FPR|                 TPR|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|                 0.0|\n",
      "|6.530816501272877E-4|0.006604622433660078|\n",
      "|0.001156789114147...|0.012711463777171344|\n",
      "|0.001686567374644...|0.018969253817302825|\n",
      "|0.002511404743704...|0.028100930180212487|\n",
      "|0.003109967275411566| 0.03440828239457486|\n",
      "|0.003947348140889864|0.042787528861354805|\n",
      "|0.004679298049543696| 0.04977800618879374|\n",
      "| 0.00548175388577843| 0.05720410623641764|\n",
      "|0.006301426285724...| 0.06447247106563868|\n",
      "|0.007105275843783788| 0.07126027817438657|\n",
      "|0.007976679918501706| 0.07839358093752405|\n",
      "| 0.00888013959517792| 0.08550307946137845|\n",
      "|0.009669314082263692|  0.0917498156970912|\n",
      "|0.010594417439034508| 0.09876060117683429|\n",
      "|0.011936325604899867| 0.10818492058509895|\n",
      "|0.013062698789823142|  0.1158453612863996|\n",
      "|0.014257446327772547|  0.1237091919890046|\n",
      "|0.015475559202187718| 0.13118912149349546|\n",
      "|0.016606933388951032| 0.13801764773293926|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.7706566094456871\n",
      "Row(max(F-Measure)=0.7923288154231001)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionModel' object has no attribute 'setThreshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-abc064e57945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbestThreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfMeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfMeasure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'F-Measure'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmaxFMeasure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max(F-Measure)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mlrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestThreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionModel' object has no attribute 'setThreshold'"
     ]
    }
   ],
   "source": [
    "trainingSummary = lrbestModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "print(maxFMeasure)\n",
    "\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "    \n",
    "lrModel.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(lrbestModel.summary.roc.select('FPR').collect(),\n",
    "         lrbestModel.summary.roc.select('TPR').collect())\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "transformed = lrbestModel.transform(test_df)\n",
    "\n",
    "results = transformed.select(['prediction', 'played_or_not'])\n",
    "predictionAndLabels=results\n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|            features|played_or_not|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "|(37,[0,1,2,3,4,5,...|            1|[-0.5275915085578...|[0.37107880539092...|       1.0|\n",
      "|(37,[0,1,2,3,4,5,...|            1|[-0.2163931622497...|[0.44611182614903...|       1.0|\n",
      "|(37,[0,1,2,3,4,5,...|            1|[-0.0680174750095...|[0.48300218393434...|       1.0|\n",
      "|(37,[0,1,2,3,4,5,...|            1|[-0.5111459481584...|[0.37492492697711...|       1.0|\n",
      "+--------------------+-------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.limit(4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- played_or_not: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = results.filter((results.prediction==1) & (results.played_or_not==1)).count()\n",
    "FP = results.filter((results.prediction==1) & (results.played_or_not!=1)).count()\n",
    "TN = results.filter((results.prediction==0) & (results.played_or_not==0)).count()\n",
    "FN = results.filter((results.prediction==0) & (results.played_or_not!=0)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6434587 1909805 3316757 1904835 0.7711271234620809 0.7715866879023511 0.7713568372315827\n"
     ]
    }
   ],
   "source": [
    "pr = TP/(TP+FP)\n",
    "rc = TP/(TP+FN)\n",
    "f1 = (2*pr*rc)/(pr+rc)\n",
    "print(TP,FP,TN,FN,pr,rc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement RandomForest Classifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"played_or_not\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [10],\n",
    "              \"min_samples_split\": [10],\n",
    "              \"min_samples_leaf\": [10],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"],\n",
    "              \"n_estimators\": [10]}\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"played_or_not\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "cv_rf = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=2)\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "rf_fit = rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+\n",
      "|prediction|played_or_not|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "F1 on train data = 0.73465\n",
      "19133488 6576139 6148984 1825453 0.744214919959749 0.9129033761772601 0.8199732205196439\n"
     ]
    }
   ],
   "source": [
    "###rfbestModel = rf_fit.bestModel\n",
    "\n",
    "results = rf_fit.transform(train_df)\n",
    "results.select('prediction', 'played_or_not', 'features').show(5)\n",
    "\n",
    "f1 = evaluator.evaluate(results)\n",
    "print(\"\\nF1 on train data = %g\" % f1)\n",
    "\n",
    "TP = results.filter((results.prediction==1) & (results.played_or_not==1)).count()\n",
    "FP = results.filter((results.prediction==1) & (results.played_or_not!=1)).count()\n",
    "TN = results.filter((results.prediction==0) & (results.played_or_not==0)).count()\n",
    "FN = results.filter((results.prediction==0) & (results.played_or_not!=0)).count()\n",
    "\n",
    "pr = TP/(TP+FP)\n",
    "rc = TP/(TP+FN)\n",
    "f1 = (2*pr*rc)/(pr+rc)\n",
    "print(TP,FP,TN,FN,pr,rc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+\n",
      "|prediction|played_or_not|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "|       1.0|            1|(36,[0,1,2,3,4,5,...|\n",
      "+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "F1 on train data = 0.730671\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "predictions_test = rf_fit.transform(test_df)\n",
    "predictions_test.select('prediction', 'played_or_not', 'features').show(5)\n",
    "\n",
    "f1 = evaluator.evaluate(predictions_test)\n",
    "print(\"\\nF1 on train data = %g\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(lrbestModel.summary.roc.select('FPR').collect(),\n",
    "         lrbestModel.summary.roc.select('TPR').collect())\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7588084 2693208 2533714 745087 0.7380477084008508 0.9105878182506996 0.8152890577611613\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "transformed = rf_fit.transform(test_df)\n",
    "\n",
    "results_rf = transformed.select(['prediction', 'played_or_not'])\n",
    "predictionAndLabels=results_rf.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Overall statistics\n",
    "TP = results_rf.filter((results_rf.prediction==1) & (results_rf.played_or_not==1)).count()\n",
    "FP = results_rf.filter((results_rf.prediction==1) & (results_rf.played_or_not!=1)).count()\n",
    "TN = results_rf.filter((results_rf.prediction==0) & (results_rf.played_or_not==0)).count()\n",
    "FN = results_rf.filter((results_rf.prediction==0) & (results_rf.played_or_not!=0)).count()\n",
    "\n",
    "pr = TP/(TP+FP)\n",
    "rc = TP/(TP+FN)\n",
    "f1 = (2*pr*rc)/(pr+rc)\n",
    "print(TP,FP,TN,FN,pr,rc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('app_id', 0.18030579349020562),\n",
       " ('price', 0.052442408753893936),\n",
       " ('requiredAge', 0.007699913259432337),\n",
       " ('isMultiplayer', 0.003478697786304344),\n",
       " ('achivements_cnt', 0.1226161830490817),\n",
       " ('Indie', 0.003211549608079511),\n",
       " ('Other', 0.0004116671842941346),\n",
       " ('Sports', 1.8418254412799813e-05),\n",
       " ('Simulation', 0.0),\n",
       " ('Strategy', 0.00012612944552430237),\n",
       " ('RPG', 0.001221428097685736),\n",
       " ('Violent', 0.0),\n",
       " ('Casual', 0.0),\n",
       " ('Adventure', 0.0),\n",
       " ('Early Access', 0.0),\n",
       " ('Action', 0.003370402702154244),\n",
       " ('Free to Play', 0.002913056304380445),\n",
       " ('total_playtime_forever', 0.019610596359290612),\n",
       " ('total_games_owned', 0.0010781985387321707),\n",
       " ('total_playtime_2weeks', 1.1492016921713716e-06),\n",
       " ('total_games_not_played', 0.0355406699651781),\n",
       " ('total_games_played', 0.0514592016036887),\n",
       " ('pct_games_played', 0.42822918022304285),\n",
       " ('Indie_Cnt', 0.007828543967610822),\n",
       " ('Other_Cnt', 0.00026190509261707644),\n",
       " ('Sports_Cnt', 0.00038701626270018686),\n",
       " ('Simulation_Cnt', 0.0),\n",
       " ('Strategy_Cnt', 0.017326136066954177),\n",
       " ('RPG_Cnt', 0.0022787571551775333),\n",
       " ('Violent_Cnt', 0.0),\n",
       " ('Casual_Cnt', 0.006646180424552226),\n",
       " ('Adventure_Cnt', 0.010774462357163046),\n",
       " ('EarlyAccess_Cnt', 8.312529452351807e-05),\n",
       " ('Action_Cnt', 0.028190972983439384),\n",
       " ('FreetoPlay_Cnt', 0.004637866955779044),\n",
       " ('positiveReviewPercent', 0.00785038961240912)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(vectorAssembler.getInputCols(), rf_fit.featureImportances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(36, {0: 0.1803, 1: 0.0524, 2: 0.0077, 3: 0.0035, 4: 0.1226, 5: 0.0032, 6: 0.0004, 7: 0.0, 9: 0.0001, 10: 0.0012, 15: 0.0034, 16: 0.0029, 17: 0.0196, 18: 0.0011, 19: 0.0, 20: 0.0355, 21: 0.0515, 22: 0.4282, 23: 0.0078, 24: 0.0003, 25: 0.0004, 27: 0.0173, 28: 0.0023, 30: 0.0066, 31: 0.0108, 32: 0.0001, 33: 0.0282, 34: 0.0046, 35: 0.0079})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_fit.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hj_models_edit_jimv2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
